learning_rate : 0.0001
max_steps : 20
batch_size : 32
eval_freq : 500
data_dir : ./cifar10/cifar-10-batches-py
--------------Convnet initialized------------
Traceback (most recent call last):
  File "train_convnet_pytorch.py", line 182, in <module>
    main()
  File "train_convnet_pytorch.py", line 165, in main
    train()
  File "train_convnet_pytorch.py", line 110, in train
    test_output = cnn(X_test)
  File "/home/lgpu0062/.conda/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0062/DeepLearningUvA/Assignment 1/code/convnet_pytorch.py", line 128, in forward
    out = layer(out)
  File "/home/lgpu0062/.conda/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0062/.conda/envs/dl/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 343, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home/lgpu0062/.conda/envs/dl/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 340, in conv2d_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 626.00 MiB (GPU 0; 10.92 GiB total capacity; 10.22 GiB already allocated; 149.50 MiB free; 8.27 MiB cached)
srun: error: r30n1: task 0: Exited with exit code 1
